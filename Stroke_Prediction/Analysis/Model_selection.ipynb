{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e44a19",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c46cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cbd6c4",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd27771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = pd.read_csv('preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0350258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=2e63cce9-ca6b-4437-b872-455435edaafc style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('2e63cce9-ca6b-4437-b872-455435edaafc').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>70.09</td>\n",
       "      <td>27.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>94.39</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58.57</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80.43</td>\n",
       "      <td>29.7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.46</td>\n",
       "      <td>36.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0       1  67.0             0              1             1          2   \n",
       "1       1  80.0             0              1             1          2   \n",
       "2       0  49.0             0              0             1          2   \n",
       "3       0  79.0             1              0             1          3   \n",
       "4       1  81.0             0              0             1          2   \n",
       "5       1  74.0             1              1             1          2   \n",
       "6       0  69.0             0              0             0          2   \n",
       "7       0  78.0             0              0             1          2   \n",
       "8       0  81.0             1              0             1          2   \n",
       "9       0  61.0             0              1             1          0   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0               1             228.69  36.6               1       1  \n",
       "1               0             105.92  32.5               2       1  \n",
       "2               1             171.23  34.4               3       1  \n",
       "3               0             174.12  24.0               2       1  \n",
       "4               1             186.21  29.0               1       1  \n",
       "5               0              70.09  27.4               2       1  \n",
       "6               1              94.39  22.8               2       1  \n",
       "7               1              58.57  24.2               0       1  \n",
       "8               0              80.43  29.7               2       1  \n",
       "9               0             120.46  36.8               3       1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef28c45",
   "metadata": {},
   "source": [
    "## Declaring Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e297f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_preprocessed['stroke']\n",
    "x = data_preprocessed.drop(['stroke'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb6a3b9",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea64fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "std.fit(x)\n",
    "x_scaled = std.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02572827",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6fb3425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module for the split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the variables with an 80-20 split and some random state\n",
    "# To have the same split as mine, use random_state = 365\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d695dd82",
   "metadata": {},
   "source": [
    "## Model testing on 8 differnt models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "234be8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b917cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2c83884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1de16975",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "x_train_res, y_train_res = sm.fit_resample(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29cc9450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regreesion :\n",
      "[[707 235]\n",
      " [  8  32]]\n",
      "Accuracy Score:  0.7525458248472505\n",
      "\n",
      "K-Fold Validation Mean Accuracy: 78.20 %\n",
      "\n",
      "Standard Deviation: 1.21 %\n",
      "\n",
      "ROC AUC Score: 0.78\n",
      "\n",
      "Precision: 0.12\n",
      "\n",
      "Recall: 0.80\n",
      "\n",
      "F1: 0.21\n",
      "-----------------------------------\n",
      "\n",
      "SVM :\n",
      "[[749 193]\n",
      " [ 16  24]]\n",
      "Accuracy Score:  0.7871690427698574\n",
      "\n",
      "K-Fold Validation Mean Accuracy: 85.49 %\n",
      "\n",
      "Standard Deviation: 0.82 %\n",
      "\n",
      "ROC AUC Score: 0.70\n",
      "\n",
      "Precision: 0.11\n",
      "\n",
      "Recall: 0.60\n",
      "\n",
      "F1: 0.19\n",
      "-----------------------------------\n",
      "\n",
      "KNeighbors :\n",
      "[[808 134]\n",
      " [ 27  13]]\n",
      "Accuracy Score:  0.8360488798370672\n",
      "\n",
      "K-Fold Validation Mean Accuracy: 91.39 %\n",
      "\n",
      "Standard Deviation: 1.14 %\n",
      "\n",
      "ROC AUC Score: 0.59\n",
      "\n",
      "Precision: 0.09\n",
      "\n",
      "Recall: 0.33\n",
      "\n",
      "F1: 0.14\n",
      "-----------------------------------\n",
      "\n",
      "GaussianNB :\n",
      "[[705 237]\n",
      " [  9  31]]\n",
      "Accuracy Score:  0.7494908350305499\n",
      "\n",
      "K-Fold Validation Mean Accuracy: 76.40 %\n",
      "\n",
      "Standard Deviation: 1.05 %\n",
      "\n",
      "ROC AUC Score: 0.76\n",
      "\n",
      "Precision: 0.12\n",
      "\n",
      "Recall: 0.78\n",
      "\n",
      "F1: 0.20\n",
      "-----------------------------------\n",
      "\n",
      "BernoulliNB :\n",
      "[[553 389]\n",
      " [ 10  30]]\n",
      "Accuracy Score:  0.5936863543788188\n",
      "\n",
      "K-Fold Validation Mean Accuracy: 72.98 %\n",
      "\n",
      "Standard Deviation: 1.19 %\n",
      "\n",
      "ROC AUC Score: 0.67\n",
      "\n",
      "Precision: 0.07\n",
      "\n",
      "Recall: 0.75\n",
      "\n",
      "F1: 0.13\n",
      "-----------------------------------\n",
      "\n",
      "Decision Tree :\n",
      "[[856  86]\n",
      " [ 35   5]]\n",
      "Accuracy Score:  0.8767820773930753\n",
      "\n",
      "K-Fold Validation Mean Accuracy: 92.75 %\n",
      "\n",
      "Standard Deviation: 3.02 %\n",
      "\n",
      "ROC AUC Score: 0.52\n",
      "\n",
      "Precision: 0.05\n",
      "\n",
      "Recall: 0.12\n",
      "\n",
      "F1: 0.08\n",
      "-----------------------------------\n",
      "\n",
      "Random Forest :\n",
      "[[923  19]\n",
      " [ 37   3]]\n",
      "Accuracy Score:  0.9429735234215886\n",
      "\n",
      "K-Fold Validation Mean Accuracy: 97.19 %\n",
      "\n",
      "Standard Deviation: 2.36 %\n",
      "\n",
      "ROC AUC Score: 0.53\n",
      "\n",
      "Precision: 0.14\n",
      "\n",
      "Recall: 0.07\n",
      "\n",
      "F1: 0.10\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost :\n",
      "[[926  16]\n",
      " [ 38   2]]\n",
      "Accuracy Score:  0.945010183299389\n",
      "\n",
      "K-Fold Validation Mean Accuracy: 96.61 %\n",
      "\n",
      "Standard Deviation: 5.55 %\n",
      "\n",
      "ROC AUC Score: 0.52\n",
      "\n",
      "Precision: 0.11\n",
      "\n",
      "Recall: 0.05\n",
      "\n",
      "F1: 0.07\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(['Logistic Regreesion', LogisticRegression(random_state=0)])\n",
    "models.append(['SVM', SVC(random_state=0)])\n",
    "models.append(['KNeighbors', KNeighborsClassifier()])\n",
    "models.append(['GaussianNB', GaussianNB()])\n",
    "models.append(['BernoulliNB', BernoulliNB()])\n",
    "models.append(['Decision Tree', DecisionTreeClassifier(random_state=0)])\n",
    "models.append(['Random Forest', RandomForestClassifier(random_state=0)])\n",
    "models.append(['XGBoost', XGBClassifier(eval_metric= 'error')])\n",
    "\n",
    "lst_1= []\n",
    "\n",
    "for m in range(len(models)):\n",
    "    lst_2= []\n",
    "    model = models[m][1]\n",
    "    model.fit(x_train_res, y_train_res)\n",
    "    y_pred = model.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)  #Confusion Matrix\n",
    "    accuracies = cross_val_score(estimator = model, X = x_train_res, y = y_train_res, cv = 10)   #K-Fold Validation\n",
    "    roc = roc_auc_score(y_test, y_pred)  #ROC AUC Score\n",
    "    precision = precision_score(y_test, y_pred)  #Precision Score\n",
    "    recall = recall_score(y_test, y_pred)  #Recall Score\n",
    "    f1 = f1_score(y_test, y_pred)  #F1 Score\n",
    "    print(models[m][0],':')\n",
    "    print(cm)\n",
    "    print('Accuracy Score: ',accuracy_score(y_test, y_pred))\n",
    "    print('')\n",
    "    print(\"K-Fold Validation Mean Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print('')\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "    print('')\n",
    "    print('ROC AUC Score: {:.2f}'.format(roc))\n",
    "    print('')\n",
    "    print('Precision: {:.2f}'.format(precision))\n",
    "    print('')\n",
    "    print('Recall: {:.2f}'.format(recall))\n",
    "    print('')\n",
    "    print('F1: {:.2f}'.format(f1))\n",
    "    print('-----------------------------------')\n",
    "    print('')\n",
    "    lst_2.append(models[m][0])\n",
    "    lst_2.append((accuracy_score(y_test, y_pred))*100) \n",
    "    lst_2.append(accuracies.mean()*100)\n",
    "    lst_2.append(accuracies.std()*100)\n",
    "    lst_2.append(roc)\n",
    "    lst_2.append(precision)\n",
    "    lst_2.append(recall)\n",
    "    lst_2.append(f1)\n",
    "    lst_1.append(lst_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38413922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lst_1, columns= ['Model', 'Accuracy', 'K-Fold Mean Accuracy', 'Std. Deviation', 'ROC AUC', 'Precision', 'Recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12488cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by= ['Accuracy', 'K-Fold Mean Accuracy'], inplace= True, ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fc6e9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=140b1f77-fbec-4959-bb6c-d3de5643bb56 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('140b1f77-fbec-4959-bb6c-d3de5643bb56').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>K-Fold Mean Accuracy</th>\n",
       "      <th>Std. Deviation</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>94.501018</td>\n",
       "      <td>96.607555</td>\n",
       "      <td>5.553394</td>\n",
       "      <td>0.516507</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>94.297352</td>\n",
       "      <td>97.192431</td>\n",
       "      <td>2.359264</td>\n",
       "      <td>0.527415</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>87.678208</td>\n",
       "      <td>92.747489</td>\n",
       "      <td>3.015320</td>\n",
       "      <td>0.516852</td>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.076336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>83.604888</td>\n",
       "      <td>91.389158</td>\n",
       "      <td>1.137750</td>\n",
       "      <td>0.591375</td>\n",
       "      <td>0.088435</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.139037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>78.716904</td>\n",
       "      <td>85.493650</td>\n",
       "      <td>0.823754</td>\n",
       "      <td>0.697558</td>\n",
       "      <td>0.110599</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.186770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regreesion</td>\n",
       "      <td>75.254582</td>\n",
       "      <td>78.200591</td>\n",
       "      <td>1.212671</td>\n",
       "      <td>0.775265</td>\n",
       "      <td>0.119850</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.208469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>74.949084</td>\n",
       "      <td>76.403979</td>\n",
       "      <td>1.054285</td>\n",
       "      <td>0.761704</td>\n",
       "      <td>0.115672</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.201299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>59.368635</td>\n",
       "      <td>72.983451</td>\n",
       "      <td>1.187622</td>\n",
       "      <td>0.668524</td>\n",
       "      <td>0.071599</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.130719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                 Model   Accuracy  K-Fold Mean Accuracy  Std. Deviation  \\\n",
       "7              XGBoost  94.501018             96.607555        5.553394   \n",
       "6        Random Forest  94.297352             97.192431        2.359264   \n",
       "5        Decision Tree  87.678208             92.747489        3.015320   \n",
       "2           KNeighbors  83.604888             91.389158        1.137750   \n",
       "1                  SVM  78.716904             85.493650        0.823754   \n",
       "0  Logistic Regreesion  75.254582             78.200591        1.212671   \n",
       "3           GaussianNB  74.949084             76.403979        1.054285   \n",
       "4          BernoulliNB  59.368635             72.983451        1.187622   \n",
       "\n",
       "    ROC AUC  Precision  Recall        F1  \n",
       "7  0.516507   0.111111   0.050  0.068966  \n",
       "6  0.527415   0.136364   0.075  0.096774  \n",
       "5  0.516852   0.054945   0.125  0.076336  \n",
       "2  0.591375   0.088435   0.325  0.139037  \n",
       "1  0.697558   0.110599   0.600  0.186770  \n",
       "0  0.775265   0.119850   0.800  0.208469  \n",
       "3  0.761704   0.115672   0.775  0.201299  \n",
       "4  0.668524   0.071599   0.750  0.130719  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f661e",
   "metadata": {},
   "source": [
    "#### Looks like Random Forest classifier and XGBoost classifier both gave us very good results. Lets do some hyperparameter tuning to see if we can come to a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82549b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c98f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_models = [(LogisticRegression(),[{'C':[0.25,0.5,0.75,1],'random_state':[0]}]), \n",
    "               (KNeighborsClassifier(),[{'n_neighbors':[5,7,8,10], 'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}]), \n",
    "               (SVC(),[{'C':[0.25,0.5,0.75,1],'kernel':['linear', 'rbf'],'random_state':[0]}]), \n",
    "               (GaussianNB(),[{'var_smoothing': [1e-09]}]), \n",
    "               (BernoulliNB(), [{'alpha': [0.25, 0.5, 1]}]), \n",
    "               (DecisionTreeClassifier(),[{'criterion':['gini','entropy'],'random_state':[0]}]), \n",
    "               (RandomForestClassifier(),[{'n_estimators':[100,150,200],'criterion':['gini','entropy'],'random_state':[0]}]), \n",
    "              (XGBClassifier(), [{'learning_rate': [0.01, 0.05, 0.1], 'eval_metric': ['error']}])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99797cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression():\n",
      "Best Accuracy : 78.24%\n",
      "Best Parameters :  {'C': 0.25, 'random_state': 0}\n",
      "\n",
      "----------------\n",
      "\n",
      "KNeighborsClassifier():\n",
      "Best Accuracy : 92.56%\n",
      "Best Parameters :  {'metric': 'manhattan', 'n_neighbors': 5}\n",
      "\n",
      "----------------\n",
      "\n",
      "SVC():\n",
      "Best Accuracy : 85.49%\n",
      "Best Parameters :  {'C': 1, 'kernel': 'rbf', 'random_state': 0}\n",
      "\n",
      "----------------\n",
      "\n",
      "GaussianNB():\n",
      "Best Accuracy : 76.40%\n",
      "Best Parameters :  {'var_smoothing': 1e-09}\n",
      "\n",
      "----------------\n",
      "\n",
      "BernoulliNB():\n",
      "Best Accuracy : 72.98%\n",
      "Best Parameters :  {'alpha': 0.25}\n",
      "\n",
      "----------------\n",
      "\n",
      "DecisionTreeClassifier():\n",
      "Best Accuracy : 93.80%\n",
      "Best Parameters :  {'criterion': 'entropy', 'random_state': 0}\n",
      "\n",
      "----------------\n",
      "\n",
      "RandomForestClassifier():\n",
      "Best Accuracy : 97.26%\n",
      "Best Parameters :  {'criterion': 'entropy', 'n_estimators': 200, 'random_state': 0}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None):\n",
      "Best Accuracy : 95.34%\n",
      "Best Parameters :  {'eval_metric': 'error', 'learning_rate': 0.1}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,j in grid_models:\n",
    "    grid = GridSearchCV(estimator=i,param_grid = j, scoring = 'accuracy',cv = 10)\n",
    "    grid.fit(x_train_res, y_train_res)\n",
    "    best_accuracy = grid.best_score_\n",
    "    best_param = grid.best_params_\n",
    "    print('{}:\\nBest Accuracy : {:.2f}%'.format(i,best_accuracy*100))\n",
    "    print('Best Parameters : ',best_param)\n",
    "    print('')\n",
    "    print('----------------')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a3425",
   "metadata": {},
   "source": [
    "#### Looks like Random forest classifier gave the best accuracy with the given hyperparamemters. So we are going to use the same model for our purpose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
